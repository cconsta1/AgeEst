{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cconsta1/AgeEst/blob/main/age_estimation_dataset_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrEgy_QP-aA7"
      },
      "source": [
        "# **Importing and installing all the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL7XGyB0AvFs"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-optimize git+https://github.com/hyperopt/hyperopt-sklearn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip freeze"
      ],
      "metadata": {
        "id": "vhl9v0lnPDGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BURIzQMk-aA9"
      },
      "outputs": [],
      "source": [
        "# Google colab\n",
        "\n",
        "from google.colab import data_table\n",
        "from google.colab import files\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "# hyperopt\n",
        "\n",
        "import hyperopt\n",
        "\n",
        "from hyperopt import tpe\n",
        "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\n",
        "from hpsklearn.components import all_classifiers, all_preprocessing, any_classifier, any_preprocessing, \\\n",
        "any_regressor, all_regressors\n",
        "\n",
        "\n",
        "# Hyperparameter optimization\n",
        "\n",
        "import skopt\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "# system\n",
        "\n",
        "import os\n",
        "import io\n",
        "\n",
        "# data analysis and plotting\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import zscore, shapiro\n",
        "from random import randint\n",
        "\n",
        "# data processing and model validation\n",
        "\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, Normalizer, MinMaxScaler\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, \\\n",
        "accuracy_score, classification_report, log_loss, mean_absolute_error, mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold, KFold, \\\n",
        "LeaveOneOut, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "\n",
        "# classification libraries\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel, Matern, RationalQuadratic\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, \\\n",
        "ExtraTreesRegressor, ExtraTreesClassifier, RandomForestRegressor\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Importing imputation libs. \n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "\n",
        "# Missing data models\n",
        "\n",
        "from itertools import combinations\n",
        "from joblib import parallel_backend\n",
        "\n",
        "# Export models into pickle\n",
        "import pickle\n",
        "\n",
        "# Various parameter settings\n",
        "\n",
        "#%matplotlib inline\n",
        "\n",
        "# To install sklearn type \"pip install numpy scipy scikit-learn\" to the anaconda terminal\n",
        "\n",
        "# To change scientific numbers to float\n",
        "#np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "# Increases the size of sns plots\n",
        "#sns.set(rc={'figure.figsize':(12,10)})\n",
        "\n",
        "# import sys\n",
        "# !conda list Check the packages installed\n",
        "\n",
        "# Displaying all the rows/columns in a data set (the default option is not to show them)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuRvt9Vv-aA_"
      },
      "source": [
        "# **Importing and preparing the data for the analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhW6bRHYBJ4P"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjiE8KVhBWRU"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_csv(io.BytesIO(uploaded['age_dataset.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UPg9uJF-aBA"
      },
      "outputs": [],
      "source": [
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5BVGEOF-aBB"
      },
      "outputs": [],
      "source": [
        "df = raw_data.iloc[:,[2, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 38, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QtP5_h2-aBC"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(df.values[3:], columns=df.iloc[2])\n",
        "\n",
        "df = df.astype(int)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR8_DpUa-aBD"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GS2-YI6-aBH"
      },
      "outputs": [],
      "source": [
        "# Add a new target vector called age groups\n",
        "\n",
        "df['Age_groups'] = pd.cut(df['Age'], bins=[10,35,50,100], labels=False)\n",
        "\n",
        "df = df.astype(int)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xRImeyg-aBJ"
      },
      "outputs": [],
      "source": [
        "# View the data as a table\n",
        "\n",
        "data_table.DataTable(df, include_index=False, num_rows_per_page=10, max_columns=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables dictionary**"
      ],
      "metadata": {
        "id": "B8E4yJm_Gg69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmSk6LJ--aBJ"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars = {\n",
        "    \"Suchey Brooks 1990\": [\n",
        "        'Right Phase Suchey'\n",
        "        ],\n",
        "    \"Meindl and Lovejoy\": [\n",
        "        'Right 1-midlamdoid',\n",
        "        '2-lambda', \n",
        "        '3-obelion', \n",
        "        '4-anterior sagital',\n",
        "        '5-bregma', \n",
        "        'Right 6-midcoronal', \n",
        "        'Right 7-pterion',\n",
        "        'Right 8-sphenofrontal', \n",
        "        'Right 9-inferior sphenotemporal', \n",
        "        'Right 10-superior sphenotemporal'\n",
        "        ],\n",
        "    \"Lovejoy et al\": [\n",
        "        \"Right Phase\"\n",
        "    ],\n",
        "    \"Buckberry and Chamberlain\": [\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes'\n",
        "        ],\n",
        "    \"Suchey Brooks 1990 and Lovejoy et al\": [\n",
        "        'Right Phase Suchey',\n",
        "        'Right Phase' \n",
        "    ],\n",
        "    \"Suchey Brooks 1990 and Buckberry Chamberlain\": [\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes',\n",
        "        'Right Phase Suchey'\n",
        "    ],\n",
        "    \"All\": [\n",
        "        'Right Phase Suchey',\n",
        "        'Right 1-midlamdoid',\n",
        "        '2-lambda', \n",
        "        '3-obelion', \n",
        "        '4-anterior sagital',\n",
        "        '5-bregma', \n",
        "        'Right 6-midcoronal', \n",
        "        'Right 7-pterion',\n",
        "        'Right 8-sphenofrontal', \n",
        "        'Right 9-inferior sphenotemporal', \n",
        "        'Right 10-superior sphenotemporal',\n",
        "        \"Right Phase\",\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes',\n",
        "        'Right Phase Suchey',\n",
        "        'Right Phase',\n",
        "        'Right Transverse organization',\n",
        "        'Right Surface texture',\n",
        "        'Right Microposity', \n",
        "        'Right Macroporositty', \n",
        "        'Right Apical changes',\n",
        "        'Right Phase Suchey'\n",
        "    ]\n",
        "} \n"
      ],
      "metadata": {
        "id": "UfSIif6wM9CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars"
      ],
      "metadata": {
        "id": "l3LjG5WnvOuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification (sklearn)** "
      ],
      "metadata": {
        "id": "mpVJkJpvGGuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in vars.items():\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  filename = 'classification_right_women_'+key.replace(\" \",\"_\")+\".dat\"\n",
        "  infofilename = 'classification_right_women_'+key.replace(\" \",\"_\")+\".txt\"\n",
        "\n",
        "  file = open(infofilename, \"w\")\n",
        "\n",
        "  model = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing=any_preprocessing('pre'), \\\n",
        "                          algo=tpe.suggest, max_evals=75, trial_timeout=30, continuous_loss_fn=False, loss_fn=mean_absolute_error)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  result_loocv = cross_val_score(estimator=pipe, X=X, y=y, scoring='accuracy', cv=LeaveOneOut(), error_score='raise')\n",
        "\n",
        "  pickle.dump(pipe, open(filename, \"wb\"))\n",
        "\n",
        "  file.write(\"---------------------------------\\n\")\n",
        "  file.write(key + '\\n')\n",
        "\n",
        "  file.write(\"Dataset size: \"+ str(len(X))+' '+ str(len(y))+'\\n')\n",
        "\n",
        "  file.write(\"Best classifier: \" + str(model.best_model()) + '\\n')\n",
        "\n",
        "\n",
        "  file.write(\"\\nAccuracy: \"+ str(acc) +'\\n')\n",
        "  \n",
        "  file.write(\"\\nConfusion matrix: \\n\" + str(cnfm) + '\\n')\n",
        "\n",
        "  file.write(\"LOOCV accuracy: \" + str(result_loocv.mean()) + '\\n')\n",
        "\n",
        "  # Close the file\n",
        "  file.close()\n"
      ],
      "metadata": {
        "id": "iaZSzTzBt7SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "R1A9EpD70Fd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('classification_right_women_Suchey_Brooks_1990.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "jnRAzV8I4ogz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression (sklearn)**"
      ],
      "metadata": {
        "id": "TXVJvjEpy3h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age'].values\n",
        "\n",
        "for key, value in vars.items():\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "  filename = 'regression_right_women_'+key.replace(\" \",\"_\")+'.dat'\n",
        "  infofilename = 'regression_right_women_'+key.replace(\" \",\"_\")+\".txt\"\n",
        "\n",
        "  file = open(infofilename, \"w\")\n",
        "\n",
        "  model = HyperoptEstimator(regressor=any_regressor('reg'), preprocessing=any_preprocessing('pre'), \\\n",
        "                          algo=tpe.suggest, max_evals=75, loss_fn=mean_absolute_error, trial_timeout=30,continuous_loss_fn=False)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  # summarize performance\n",
        "  acc = model.score(X_test, y_test)\n",
        "\n",
        "  pipe = Pipeline([('scaler', model.best_model()['preprocs'][0] ), ('clf', model.best_model()['learner'] )])\n",
        "\n",
        "  pipe.fit(X, y)\n",
        "\n",
        "  pickle.dump(pipe, open(filename, \"wb\"))\n",
        "\n",
        "  file.write(\"---------------------------------\\n\")\n",
        "  file.write(key + '\\n')\n",
        "\n",
        "  file.write(\"Dataset size: \"+ str(len(X))+' '+ str(len(y))+'\\n')\n",
        "\n",
        "  file.write(\"Best classifier: \" + str(model.best_model()) + '\\n')\n",
        "\n",
        "  file.write(\"\\nAccuracy: \"+ str(acc) +'\\n')\n",
        "\n",
        "  # Close the file\n",
        "  file.close()\n"
      ],
      "metadata": {
        "id": "GbmBCg0Hzs5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "37TC3UV483z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.predict(X_test),'ro')\n",
        "plt.plot(y_test,'b*')"
      ],
      "metadata": {
        "id": "X913zTok90a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**"
      ],
      "metadata": {
        "id": "8uDLUTRI_EpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "gXPaGsqn_K5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification (tensorflow)**"
      ],
      "metadata": {
        "id": "7fytY3R9CJ2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age_groups'].values\n",
        "\n",
        "for key, value in vars.items():\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25, stratify=y)\n",
        "\n",
        "  modelfilename = 'ann_classification_right_women_'+key.replace(\" \",\"_\")+\".dat\"\n",
        "\n",
        "  infofilename = 'ann_classification_right_women_'+key.replace(\" \",\"_\")+\".txt\"\n",
        "\n",
        "  file = open(infofilename, \"w\")\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "  \n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "  model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=500, verbose = 0)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "  cnfm = confusion_matrix(y_test, model.predict(X_test).argmax(axis=-1)) \n",
        "\n",
        "  #result_loocv = cross_val_score(estimator=model, X=X, y=y, scoring='accuracy', cv=LeaveOneOut(), error_score='raise')\n",
        "\n",
        "  pickle.dump(model, open(filename, \"wb\"))\n",
        "\n",
        "  \n",
        "  file.write('\\n\\n')\n",
        "  file.write(\"---------------------------------\\n\")\n",
        "  file.write(key + '\\n')\n",
        "\n",
        "  file.write(\"Dataset size: \"+ str(len(X))+' '+ str(len(y))+'\\n')\n",
        "\n",
        "  file.write(\"\\nAccuracy: \"+ str(acc) +'\\n')\n",
        "  \n",
        "  file.write(\"\\nConfusion matrix: \\n\" + str(cnfm))\n",
        "\n",
        "  #print(\"\\nLOOCV accuracy: \", result_loocv.mean())\n",
        "\n",
        "  # Close the file\n",
        "  file.close()\n",
        "  \n"
      ],
      "metadata": {
        "id": "6DOhbGNfBBI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "aUv7Qpol5Fde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ann_classification_right_women_All.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "YN0zJ8D06YYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression**"
      ],
      "metadata": {
        "id": "RA74RsmKtru1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df[df[\"sex\"]==2]\n",
        "y = dff['Age'].values\n",
        "\n",
        "for key, value in vars.items():\n",
        "\n",
        "  X = dff[value].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size=0.25)\n",
        "\n",
        "  modelfilename = 'ann_regression_right_women_'+key.replace(\" \",\"_\")+\".dat\"\n",
        "\n",
        "  infofilename = 'ann_regression_right_women_'+key.replace(\" \",\"_\")+\".txt\"\n",
        "\n",
        "  file = open(infofilename, \"w\")\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "  \n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "  model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=500)\n",
        "\n",
        "  # summarize performance\n",
        "  acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "  pickle.dump(model, open(filename, \"wb\"))\n",
        "\n",
        "  file.write('\\n\\n')\n",
        "  file.write(\"---------------------------------\\n\")\n",
        "  file.write(key + '\\n')\n",
        "\n",
        "  file.write(\"Dataset size: \"+ str(len(X))+' '+ str(len(y))+'\\n')\n",
        "\n",
        "  file.write(\"\\nAccuracy: \"+ str(acc) +'\\n')\n",
        "\n",
        "  # Close the file\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "Pn-wklhO6pFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "VZTphYt2_o7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ann_regression_right_men_Lovejoy_et_al.txt', 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "id": "UpMuZTvTBhs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.view"
      ],
      "metadata": {
        "id": "ubYrEOTmBw5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "VPUrLLXMHBf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/*\n"
      ],
      "metadata": {
        "id": "i18Rq4TnJID_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/file.zip\")\n"
      ],
      "metadata": {
        "id": "PaalBHjjJ7rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLeoTbrBKCJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}